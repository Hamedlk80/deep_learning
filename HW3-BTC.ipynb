{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:08:09.819310Z",
     "start_time": "2025-05-29T21:07:57.437982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_date = datetime.today()\n",
    "start_date_daily = datetime(2015, 1, 1)\n",
    "start_date_hourly = end_date - timedelta(days=90)\n",
    "\n",
    "tickers = {\n",
    "    \"bitcoin\": \"BTC-USD\",\n",
    "    \"gold\": \"GC=F\",\n",
    "    \"oil\": \"CL=F\"\n",
    "}\n",
    "\n",
    "def download_data(ticker, start, end, interval):\n",
    "    return yf.download(ticker, start=start, end=end, interval=interval, auto_adjust=True)\n",
    "\n",
    "btc_daily = download_data(tickers[\"bitcoin\"], start_date_daily, end_date, \"1d\")\n",
    "gold_daily = download_data(tickers[\"gold\"], start_date_daily, end_date, \"1d\")\n",
    "oil_daily = download_data(tickers[\"oil\"], start_date_daily, end_date, \"1d\")\n",
    "\n",
    "btc_1h = download_data(tickers[\"bitcoin\"], start_date_hourly, end_date, \"1h\")\n",
    "gold_1h = download_data(tickers[\"gold\"], start_date_hourly, end_date, \"1h\")\n",
    "oil_1h = download_data(tickers[\"oil\"], start_date_hourly, end_date, \"1h\")\n",
    "\n",
    "btc_4h = download_data(tickers[\"bitcoin\"], start_date_hourly, end_date, \"4h\")\n",
    "gold_4h = download_data(tickers[\"gold\"], start_date_hourly, end_date, \"4h\")\n",
    "oil_4h = download_data(tickers[\"oil\"], start_date_hourly, end_date, \"4h\")\n",
    "\n",
    "btc_daily.to_csv(\"btc_daily.csv\")\n",
    "gold_daily.to_csv(\"gold_daily.csv\")\n",
    "oil_daily.to_csv(\"oil_daily.csv\")\n",
    "\n",
    "btc_1h.to_csv(\"btc_1h.csv\")\n",
    "gold_1h.to_csv(\"gold_1h.csv\")\n",
    "oil_1h.to_csv(\"oil_1h.csv\")\n",
    "\n",
    "btc_4h.to_csv(\"btc_4h.csv\")\n",
    "gold_4h.to_csv(\"gold_4h.csv\")\n",
    "oil_4h.to_csv(\"oil_4h.csv\")\n",
    "\n",
    "def prepare_combined_dataset(btc_df, gold_df, oil_df):\n",
    "    df = btc_df[['Close']].rename(columns={'Close': 'Close_btc'})\n",
    "    df['Close_gold'] = gold_df['Close']\n",
    "    df['Close_oil'] = oil_df['Close']\n",
    "    df.dropna(inplace=True)\n",
    "    df['Target'] = df['Close_btc'].shift(-1)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Day\"] = np.arange(1, len(df)+1)\n",
    "    return df\n",
    "\n",
    "df_1h = prepare_combined_dataset(btc_1h, gold_1h, oil_1h)\n",
    "df_4h = prepare_combined_dataset(btc_4h, gold_4h, oil_4h)\n",
    "df_1d = prepare_combined_dataset(btc_daily, gold_daily, oil_daily)\n",
    "\n",
    "# üíæ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ≥ÿßÿ≤€å ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ŸÜŸáÿß€å€å\n",
    "df_1h.to_csv(\"df_1h.csv\")\n",
    "df_4h.to_csv(\"df_4h.csv\")\n",
    "df_1d.to_csv(\"df_1d.csv\")\n"
   ],
   "id": "de1c89cf25b7a0b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:08:09.980856Z",
     "start_time": "2025-05-29T21:08:09.882593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_clean_csv(filepath):\n",
    "    df = pd.read_csv(filepath, skiprows=2)\n",
    "    expected_cols = ['Datetime', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "    df.columns = expected_cols[:df.shape[1]]\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    return df\n",
    "\n",
    "btc_1h = load_and_clean_csv(\"btc_1h_raw.csv\")\n",
    "gold_1h = load_and_clean_csv(\"gold_1h_raw.csv\")\n",
    "oil_1h = load_and_clean_csv(\"oil_1h_raw.csv\")\n",
    "\n",
    "btc_4h = load_and_clean_csv(\"btc_4h_direct.csv\")\n",
    "gold_4h = load_and_clean_csv(\"gold_4h_direct.csv\")\n",
    "oil_4h = load_and_clean_csv(\"oil_4h_direct.csv\")\n",
    "\n",
    "btc_1d = load_and_clean_csv(\"btc_daily_raw.csv\")\n",
    "gold_1d = load_and_clean_csv(\"gold_daily_raw.csv\")\n",
    "oil_1d = load_and_clean_csv(\"oil_daily_raw.csv\")\n",
    "\n",
    "btc_1h.info(), btc_1h.head(2)\n"
   ],
   "id": "4ae53d830245b52f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2157 entries, 2025-03-01 00:00:00+00:00 to 2025-05-29 20:00:00+00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       2157 non-null   float64\n",
      " 1   High       2157 non-null   float64\n",
      " 2   Low        2157 non-null   float64\n",
      " 3   Close      2157 non-null   float64\n",
      " 4   Adj Close  2157 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 101.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                                    Open          High           Low  \\\n",
       " Datetime                                                              \n",
       " 2025-03-01 00:00:00+00:00  83832.046875  84510.898438  83794.234375   \n",
       " 2025-03-01 01:00:00+00:00  84626.718750  84741.898438  83809.539062   \n",
       " \n",
       "                                   Close  Adj Close  \n",
       " Datetime                                            \n",
       " 2025-03-01 00:00:00+00:00  84330.851562          0  \n",
       " 2025-03-01 01:00:00+00:00  83809.539062          0  )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:08:10.119615Z",
     "start_time": "2025-05-29T21:08:10.043188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_full_dataset(btc_df, gold_df, oil_df):\n",
    "    btc = btc_df.add_prefix('btc_')\n",
    "    gold = gold_df.add_prefix('gold_')\n",
    "    oil = oil_df.add_prefix('oil_')\n",
    "\n",
    "    df = btc.join([gold, oil], how='inner')\n",
    "    df.dropna(inplace=True)\n",
    "    df['Day'] = range(1, len(df) + 1)\n",
    "    df['Target'] = df['btc_Close'].shift(-1)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "df_1h = prepare_full_dataset(btc_1h, gold_1h, oil_1h)\n",
    "df_4h = prepare_full_dataset(btc_4h, gold_4h, oil_4h)\n",
    "df_1d = prepare_full_dataset(btc_1d, gold_1d, oil_1d)\n",
    "\n",
    "df_1h.to_csv(\"df_1h.csv\")\n",
    "df_4h.to_csv(\"df_4h.csv\")\n",
    "df_1d.to_csv(\"df_1d.csv\")"
   ],
   "id": "c5f3d09e5bf15c28",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:09:01.050407Z",
     "start_time": "2025-05-29T21:08:10.174176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, models, metrics\n",
    "\n",
    "df_1h = pd.read_csv(\"df_1h.csv\")\n",
    "df_4h = pd.read_csv(\"df_4h.csv\")\n",
    "df_1d = pd.read_csv(\"df_1d.csv\")\n",
    "\n",
    "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
    "param_grid_dt = {'max_depth': [None]}\n",
    "param_grid_knn = {'n_neighbors': [3]}\n",
    "param_grid_ridge = {'alpha': [1.0]}\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    start_time = time.time()\n",
    "    search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    return search.best_estimator_, train_time\n",
    "\n",
    "def train_ml(df, timeframe):\n",
    "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
    "    y = df[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "    models_dict = {\n",
    "        \"Ridge\": (Ridge(), param_grid_ridge),\n",
    "        \"MLP\": (MLPRegressor(), param_grid_mlp),\n",
    "        \"LinearRegression\": (LinearRegression(), {}),\n",
    "        \"DecisionTree\": (DecisionTreeRegressor(), param_grid_dt),\n",
    "        \"KNN\": (KNeighborsRegressor(), param_grid_knn),\n",
    "        \"RandomForest\": (RandomForestRegressor(), param_grid_rf),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, (model, params) in models_dict.items():\n",
    "        if params:\n",
    "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = model\n",
    "            train_time = time.time() - start\n",
    "\n",
    "        start_pred = time.time()\n",
    "        preds = best_model.predict(X_test)\n",
    "        pred_time = time.time() - start_pred\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        acc = 1 - (mae / y_test.mean())\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Timeframe\": timeframe,\n",
    "            \"TrainTime\": train_time,\n",
    "            \"PredictTime\": pred_time,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def sequence_maker(data, window_size, target_index):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size, target_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_rnn(X, y, tf, features):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(20, features)),\n",
    "        layers.SimpleRNN(20, return_sequences=True),\n",
    "        layers.SimpleRNN(20),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam',\n",
    "        metrics=[\n",
    "            metrics.MeanSquaredError(name='mse'),\n",
    "            metrics.MeanAbsoluteError(name='mae'),\n",
    "            metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "            metrics.RootMeanSquaredError(name='rmse'),\n",
    "            metrics.R2Score(name='r2')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    start_pred = time.time()\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    pred_time = time.time() - start_pred\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"RNN\",\n",
    "        \"Timeframe\": tf,\n",
    "        \"TrainTime\": train_time,\n",
    "        \"PredictTime\": pred_time,\n",
    "        \"MAE\": results[2],\n",
    "        \"R2\": results[5],\n",
    "        \"Accuracy\": 1 - (results[2] / np.mean(y_test))\n",
    "    }\n",
    "\n",
    "def run_rnn(df, tf):\n",
    "    df = df.drop(columns=[\"Datetime\"])\n",
    "    target_col = [col for col in df.columns if col.endswith(\"btc_Close\") or col == \"Close_btc\"]\n",
    "    target_col = target_col[0] if target_col else \"Close_btc\"\n",
    "    target_index = df.columns.get_loc(target_col)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    X, y = sequence_maker(scaled, 20, target_index)\n",
    "    return train_rnn(X, y, tf, features=X.shape[2])\n",
    "\n",
    "results = []\n",
    "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
    "    results.extend(train_ml(df, tf))\n",
    "    results.append(run_rnn(df, tf))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ],
   "id": "a9641a785962a3db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.75887e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.33231e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.83966e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model Timeframe  TrainTime  PredictTime           MAE  \\\n",
      "0              Ridge        1h   3.140098     0.000000  6.056013e+01   \n",
      "1                MLP        1h   1.719354     0.000000  3.325540e+04   \n",
      "2   LinearRegression        1h   0.028105     0.002005  6.057268e+01   \n",
      "3       DecisionTree        1h   1.663918     0.000000  2.552671e+03   \n",
      "4                KNN        1h   1.562476     0.061470  1.273849e+04   \n",
      "5       RandomForest        1h   2.684246     0.000000  1.743380e+03   \n",
      "6                RNN        1h  10.086232     0.094985  5.757501e-02   \n",
      "7              Ridge        4h   1.612336     0.000000  1.456735e+02   \n",
      "8                MLP        4h   0.153385     0.015622  1.361052e+07   \n",
      "9   LinearRegression        4h   0.000000     0.000000  1.455550e+02   \n",
      "10      DecisionTree        4h   0.204224     0.000000  8.945909e+02   \n",
      "11               KNN        4h   0.073953     0.002347  1.873523e+04   \n",
      "12      RandomForest        4h   0.310917     0.012004  1.132425e+03   \n",
      "13               RNN        4h  15.932531     0.101194  1.135000e-01   \n",
      "14             Ridge        1d   0.118647     0.005542  4.815438e+02   \n",
      "15               MLP        1d   0.382674     0.000000  7.476053e+04   \n",
      "16  LinearRegression        1d   0.000000     0.000000  4.815423e+02   \n",
      "17      DecisionTree        1d   0.224506     0.000000  1.158765e+04   \n",
      "18               KNN        1d   0.095098     0.006005  4.594969e+04   \n",
      "19      RandomForest        1d   1.889933     0.015622  1.187205e+04   \n",
      "20               RNN        1d   7.839283     0.111970  2.607473e-02   \n",
      "\n",
      "              R2    Accuracy  \n",
      "0   9.916171e-01    0.999446  \n",
      "1  -1.425079e+03    0.695782  \n",
      "2   9.916191e-01    0.999446  \n",
      "3  -3.792478e+00    0.976648  \n",
      "4  -1.421824e+02    0.883469  \n",
      "5  -1.381982e+00    0.984052  \n",
      "6  -2.351670e+00    0.938364  \n",
      "7   9.386848e-01    0.998667  \n",
      "8  -4.518374e+08 -123.531472  \n",
      "9   9.388368e-01    0.998668  \n",
      "10  4.048634e-01    0.991815  \n",
      "11 -1.957529e+02    0.828579  \n",
      "12 -7.604042e-02    0.989639  \n",
      "13 -1.162546e+01    0.878487  \n",
      "14  9.952833e-01    0.993955  \n",
      "15 -2.033667e+01    0.061443  \n",
      "16  9.952833e-01    0.993955  \n",
      "17 -6.383732e-03    0.854527  \n",
      "18 -7.742033e+00    0.423139  \n",
      "19 -5.795653e-02    0.850956  \n",
      "20  9.479722e-01    0.963399  \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:09:01.283200Z",
     "start_time": "2025-05-29T21:09:01.160449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1h = pd.read_csv(\"df_1h.csv\")\n",
    "df_4h = pd.read_csv(\"df_4h.csv\")\n",
    "df_1d = pd.read_csv(\"df_1d.csv\")\n",
    "\n",
    "def process_for_classification(df):\n",
    "    df = df.drop(columns=[\"Target\"])\n",
    "    df[\"Benefit\"] = df[\"btc_Close\"] - df[\"btc_Open\"]\n",
    "    df[\"Target\"] = (df[\"Benefit\"] > 0).astype(int)\n",
    "    df[\"Target\"] = df[\"Target\"].shift(-1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_1h_cls = process_for_classification(df_1h)\n",
    "df_4h_cls = process_for_classification(df_4h)\n",
    "df_1d_cls = process_for_classification(df_1d)\n",
    "\n",
    "df_1h_cls.to_csv(\"df_1h_class.csv\", index=False)\n",
    "df_4h_cls.to_csv(\"df_4h_class.csv\", index=False)\n",
    "df_1d_cls.to_csv(\"df_1d_class.csv\", index=False)"
   ],
   "id": "35fc555ba80c5814",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:09:24.293974Z",
     "start_time": "2025-05-29T21:09:01.346804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, models, metrics\n",
    "\n",
    "df_1h = pd.read_csv(\"df_1h_class.csv\")\n",
    "df_4h = pd.read_csv(\"df_4h_class.csv\")\n",
    "df_1d = pd.read_csv(\"df_1d_class.csv\")\n",
    "\n",
    "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
    "param_grid_dt = {'max_depth': [None]}\n",
    "param_grid_knn = {'n_neighbors': [3]}\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    start_time = time.time()\n",
    "    search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    return search.best_estimator_, train_time\n",
    "\n",
    "def train_classification_models(df, timeframe):\n",
    "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
    "    y = df[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "    models_dict = {\n",
    "        \"LogisticRegression\": (LogisticRegression(max_iter=500), {}),\n",
    "        \"MLP\": (MLPClassifier(), param_grid_mlp),\n",
    "        \"DecisionTree\": (DecisionTreeClassifier(), param_grid_dt),\n",
    "        \"KNN\": (KNeighborsClassifier(), param_grid_knn),\n",
    "        \"RandomForest\": (RandomForestClassifier(), param_grid_rf),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, (model, params) in models_dict.items():\n",
    "        if params:\n",
    "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = model\n",
    "            train_time = time.time() - start\n",
    "\n",
    "        start_pred = time.time()\n",
    "        preds = best_model.predict(X_test)\n",
    "        pred_time = time.time() - start_pred\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Timeframe\": timeframe,\n",
    "            \"TrainTime\": train_time,\n",
    "            \"PredictTime\": pred_time,\n",
    "            \"Accuracy\": accuracy_score(y_test, preds),\n",
    "            \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
    "            \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
    "            \"F1\": f1_score(y_test, preds, zero_division=0)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def sequence_maker(data, window_size, target_index):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size, target_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_rnn_classifier(X, y, tf, features):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(20, features)),\n",
    "        layers.SimpleRNN(20, return_sequences=True),\n",
    "        layers.SimpleRNN(20),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=[\n",
    "            metrics.BinaryAccuracy(name='accuracy'),\n",
    "            metrics.Precision(name='precision'),\n",
    "            metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    start_pred = time.time()\n",
    "    eval_result = model.evaluate(X_test, y_test, verbose=0)\n",
    "    pred_time = time.time() - start_pred\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"RNN\",\n",
    "        \"Timeframe\": tf,\n",
    "        \"TrainTime\": train_time,\n",
    "        \"PredictTime\": pred_time,\n",
    "        \"Accuracy\": eval_result[1],\n",
    "        \"Precision\": eval_result[2],\n",
    "        \"Recall\": eval_result[3],\n",
    "        \"F1\": 2 * eval_result[2] * eval_result[3] / (eval_result[2] + eval_result[3] + 1e-10)\n",
    "    }\n",
    "\n",
    "def run_rnn(df, tf):\n",
    "    df = df.drop(columns=[\"Datetime\"])\n",
    "    target_col = \"Target\"\n",
    "    target_index = df.columns.get_loc(target_col)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    X, y = sequence_maker(scaled, 20, target_index)\n",
    "    return train_rnn_classifier(X, y, tf, features=X.shape[2])\n",
    "\n",
    "results = []\n",
    "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
    "    results.extend(train_classification_models(df, tf))\n",
    "    results.append(run_rnn(df, tf))\n",
    "\n",
    "df_results_cls = pd.DataFrame(results)\n",
    "print(df_results_cls)"
   ],
   "id": "5bb0626581cd02e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Timeframe  TrainTime  PredictTime  Accuracy  Precision  \\\n",
      "0   LogisticRegression        1h   0.041258     0.006006  0.524823   0.592593   \n",
      "1                  MLP        1h   0.249256     0.000000  0.489362   0.500000   \n",
      "2         DecisionTree        1h   0.270131     0.000000  0.482270   0.496124   \n",
      "3                  KNN        1h   0.294130     0.015631  0.496454   0.510204   \n",
      "4         RandomForest        1h   0.679449     0.016192  0.489362   0.500000   \n",
      "5                  RNN        1h   6.584813     0.086984  0.553957   0.569444   \n",
      "6   LogisticRegression        4h   0.015626     0.000000  0.514286   0.533333   \n",
      "7                  MLP        4h   0.100038     0.000000  0.542857   0.542857   \n",
      "8         DecisionTree        4h   0.152770     0.000000  0.571429   0.571429   \n",
      "9                  KNN        4h   0.227700     0.008018  0.428571   0.454545   \n",
      "10        RandomForest        4h   0.298560     0.006505  0.428571   0.000000   \n",
      "11                 RNN        4h   4.823679     0.079480  0.515152   0.516129   \n",
      "12  LogisticRegression        1d   0.013437     0.001715  0.461832   0.393443   \n",
      "13                 MLP        1d   0.195039     0.000000  0.488550   0.488550   \n",
      "14        DecisionTree        1d   0.132559     0.000000  0.545802   0.527950   \n",
      "15                 KNN        1d   0.174716     0.012523  0.496183   0.483607   \n",
      "16        RandomForest        1d   0.903110     0.000000  0.534351   0.517241   \n",
      "17                 RNN        1d   7.150005     0.088429  0.538462   0.544304   \n",
      "\n",
      "      Recall        F1  \n",
      "0   0.222222  0.323232  \n",
      "1   0.944444  0.653846  \n",
      "2   0.888889  0.636816  \n",
      "3   0.347222  0.413223  \n",
      "4   0.805556  0.617021  \n",
      "5   0.569444  0.569444  \n",
      "6   0.842105  0.653061  \n",
      "7   1.000000  0.703704  \n",
      "8   0.842105  0.680851  \n",
      "9   0.263158  0.333333  \n",
      "10  0.000000  0.000000  \n",
      "11  0.941176  0.666667  \n",
      "12  0.187500  0.253968  \n",
      "13  1.000000  0.656410  \n",
      "14  0.664062  0.588235  \n",
      "15  0.460938  0.472000  \n",
      "16  0.703125  0.596026  \n",
      "17  0.338583  0.417476  \n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:09:49.378844Z",
     "start_time": "2025-05-29T21:09:24.362434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, models, metrics\n",
    "\n",
    "df_1h = pd.read_csv(\"df_1h_class.csv\")\n",
    "df_4h = pd.read_csv(\"df_4h_class.csv\")\n",
    "df_1d = pd.read_csv(\"df_1d_class.csv\")\n",
    "\n",
    "\n",
    "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
    "param_grid_dt = {'max_depth': [None]}\n",
    "param_grid_knn = {'n_neighbors': [3]}\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    start_time = time.time()\n",
    "    search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    return search.best_estimator_, train_time\n",
    "\n",
    "def train_classification_models(df, timeframe):\n",
    "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
    "    y = df[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "    models_dict = {\n",
    "        \"LogisticRegression\": (LogisticRegression(max_iter=500), {}),\n",
    "        \"MLP\": (MLPClassifier(), param_grid_mlp),\n",
    "        \"DecisionTree\": (DecisionTreeClassifier(), param_grid_dt),\n",
    "        \"KNN\": (KNeighborsClassifier(), param_grid_knn),\n",
    "        \"RandomForest\": (RandomForestClassifier(), param_grid_rf),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, (model, params) in models_dict.items():\n",
    "        if params:\n",
    "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = model\n",
    "            train_time = time.time() - start\n",
    "\n",
    "        start_pred = time.time()\n",
    "        preds = best_model.predict(X_test)\n",
    "        pred_time = time.time() - start_pred\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Timeframe\": timeframe,\n",
    "            \"TrainTime\": train_time,\n",
    "            \"PredictTime\": pred_time,\n",
    "            \"Accuracy\": accuracy_score(y_test, preds),\n",
    "            \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
    "            \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
    "            \"F1\": f1_score(y_test, preds, zero_division=0)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def sequence_maker(data, window_size, target_index):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size, target_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_rnn_classifier(X, y, tf, features):\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(20, features)),\n",
    "        layers.SimpleRNN(20, return_sequences=True),\n",
    "        layers.SimpleRNN(20),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=[\n",
    "            metrics.BinaryAccuracy(name='accuracy'),\n",
    "            metrics.Precision(name='precision'),\n",
    "            metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    start_pred = time.time()\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "    pred_time = time.time() - start_pred\n",
    "\n",
    "    preds_df = pd.DataFrame({\n",
    "        'True': y_test.flatten(),\n",
    "        'Predicted': y_pred_class.flatten(),\n",
    "        'Probability': y_pred_prob.flatten()\n",
    "    })\n",
    "    preds_df.to_csv(f\"rnn_preds_{tf}.csv\", index=False)\n",
    "\n",
    "    acc = np.mean(y_pred_class.flatten() == y_test.flatten())\n",
    "    prec = precision_score(y_test, y_pred_class, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_class, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_class, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"RNN\",\n",
    "        \"Timeframe\": tf,\n",
    "        \"TrainTime\": train_time,\n",
    "        \"PredictTime\": pred_time,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1\n",
    "    }\n",
    "\n",
    "def run_rnn(df, tf):\n",
    "    df = df.drop(columns=[\"Datetime\"])\n",
    "    target_col = \"Target\"\n",
    "    target_index = df.columns.get_loc(target_col)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    X, y = sequence_maker(scaled, 20, target_index)\n",
    "    return train_rnn_classifier(X, y, tf, features=X.shape[2])\n",
    "\n",
    "results = []\n",
    "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
    "    results.extend(train_classification_models(df, tf))\n",
    "    results.append(run_rnn(df, tf))\n",
    "\n",
    "df_results_cls = pd.DataFrame(results)\n",
    "print(df_results_cls)"
   ],
   "id": "7b0cd93d6c31939e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FFFF5676A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step\n",
      "                 Model Timeframe  TrainTime  PredictTime  Accuracy  Precision  \\\n",
      "0   LogisticRegression        1h   0.031253     0.000000  0.524823   0.592593   \n",
      "1                  MLP        1h   0.146653     0.000000  0.482270   0.495868   \n",
      "2         DecisionTree        1h   0.101131     0.000000  0.482270   0.496124   \n",
      "3                  KNN        1h   0.136436     0.008507  0.496454   0.510204   \n",
      "4         RandomForest        1h   0.500797     0.015625  0.560284   0.559524   \n",
      "5                  RNN        1h   6.583073     0.465921  0.589928   0.641509   \n",
      "6   LogisticRegression        4h   0.031700     0.000507  0.514286   0.533333   \n",
      "7                  MLP        4h   0.122909     0.000000  0.514286   0.531250   \n",
      "8         DecisionTree        4h   0.073548     0.000000  0.514286   0.550000   \n",
      "9                  KNN        4h   0.047812     0.007704  0.428571   0.454545   \n",
      "10        RandomForest        4h   0.258842     0.000000  0.485714   0.666667   \n",
      "11                 RNN        4h   5.705184     0.385214  0.666667   0.636364   \n",
      "12  LogisticRegression        1d   0.000000     0.015630  0.461832   0.393443   \n",
      "13                 MLP        1d   0.154781     0.016194  0.511450   0.000000   \n",
      "14        DecisionTree        1d   0.109052     0.000000  0.545802   0.531469   \n",
      "15                 KNN        1d   0.166213     0.015626  0.496183   0.483607   \n",
      "16        RandomForest        1d   0.820915     0.015627  0.492366   0.486631   \n",
      "17                 RNN        1d   7.284238     1.496235  0.507692   0.493333   \n",
      "\n",
      "      Recall        F1  \n",
      "0   0.222222  0.323232  \n",
      "1   0.833333  0.621762  \n",
      "2   0.888889  0.636816  \n",
      "3   0.347222  0.413223  \n",
      "4   0.652778  0.602564  \n",
      "5   0.472222  0.544000  \n",
      "6   0.842105  0.653061  \n",
      "7   0.894737  0.666667  \n",
      "8   0.578947  0.564103  \n",
      "9   0.263158  0.333333  \n",
      "10  0.105263  0.181818  \n",
      "11  0.823529  0.717949  \n",
      "12  0.187500  0.253968  \n",
      "13  0.000000  0.000000  \n",
      "14  0.593750  0.560886  \n",
      "15  0.460938  0.472000  \n",
      "16  0.710938  0.577778  \n",
      "17  0.291339  0.366337  \n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
