{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:08:09.819310Z",
          "start_time": "2025-05-29T21:07:57.437982Z"
        },
        "id": "de1c89cf25b7a0b2",
        "outputId": "8d24a28e-ea6c-4771-9dea-04bab34b577b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "end_date = datetime.today()\n",
        "start_date_daily = datetime(2015, 1, 1)\n",
        "start_date_hourly = end_date - timedelta(days=90)\n",
        "\n",
        "tickers = {\n",
        "    \"bitcoin\": \"BTC-USD\",\n",
        "    \"gold\": \"GC=F\",\n",
        "    \"oil\": \"CL=F\"\n",
        "}\n",
        "\n",
        "def download_data(ticker, start, end, interval):\n",
        "    return yf.download(ticker, start=start, end=end, interval=interval, auto_adjust=True)\n",
        "\n",
        "btc_daily = download_data(tickers[\"bitcoin\"], start_date_daily, end_date, \"1d\")\n",
        "gold_daily = download_data(tickers[\"gold\"], start_date_daily, end_date, \"1d\")\n",
        "oil_daily = download_data(tickers[\"oil\"], start_date_daily, end_date, \"1d\")\n",
        "\n",
        "btc_1h = download_data(tickers[\"bitcoin\"], start_date_hourly, end_date, \"1h\")\n",
        "gold_1h = download_data(tickers[\"gold\"], start_date_hourly, end_date, \"1h\")\n",
        "oil_1h = download_data(tickers[\"oil\"], start_date_hourly, end_date, \"1h\")\n",
        "\n",
        "btc_4h = download_data(tickers[\"bitcoin\"], start_date_hourly, end_date, \"4h\")\n",
        "gold_4h = download_data(tickers[\"gold\"], start_date_hourly, end_date, \"4h\")\n",
        "oil_4h = download_data(tickers[\"oil\"], start_date_hourly, end_date, \"4h\")\n",
        "\n",
        "btc_daily.to_csv(\"btc_daily.csv\")\n",
        "gold_daily.to_csv(\"gold_daily.csv\")\n",
        "oil_daily.to_csv(\"oil_daily.csv\")\n",
        "\n",
        "btc_1h.to_csv(\"btc_1h.csv\")\n",
        "gold_1h.to_csv(\"gold_1h.csv\")\n",
        "oil_1h.to_csv(\"oil_1h.csv\")\n",
        "\n",
        "btc_4h.to_csv(\"btc_4h.csv\")\n",
        "gold_4h.to_csv(\"gold_4h.csv\")\n",
        "oil_4h.to_csv(\"oil_4h.csv\")\n",
        "\n",
        "def prepare_combined_dataset(btc_df, gold_df, oil_df):\n",
        "    df = btc_df[['Close']].rename(columns={'Close': 'Close_btc'})\n",
        "    df['Close_gold'] = gold_df['Close']\n",
        "    df['Close_oil'] = oil_df['Close']\n",
        "    df.dropna(inplace=True)\n",
        "    df['Target'] = df['Close_btc'].shift(-1)\n",
        "    df.dropna(inplace=True)\n",
        "    df[\"Day\"] = np.arange(1, len(df)+1)\n",
        "    return df\n",
        "\n",
        "df_1h = prepare_combined_dataset(btc_1h, gold_1h, oil_1h)\n",
        "df_4h = prepare_combined_dataset(btc_4h, gold_4h, oil_4h)\n",
        "df_1d = prepare_combined_dataset(btc_daily, gold_daily, oil_daily)\n",
        "\n",
        "# üíæ ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ≥ÿßÿ≤€å ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ŸÜŸáÿß€å€å\n",
        "df_1h.to_csv(\"df_1h.csv\")\n",
        "df_4h.to_csv(\"df_4h.csv\")\n",
        "df_1d.to_csv(\"df_1d.csv\")\n"
      ],
      "id": "de1c89cf25b7a0b2",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:08:09.980856Z",
          "start_time": "2025-05-29T21:08:09.882593Z"
        },
        "id": "4ae53d830245b52f",
        "outputId": "23625c5c-dfff-434f-cc69-ad7fa16ae0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_clean_csv(filepath):\n",
        "    df = pd.read_csv(filepath, skiprows=2)\n",
        "    expected_cols = ['Datetime', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "    df.columns = expected_cols[:df.shape[1]]\n",
        "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
        "    df.set_index('Datetime', inplace=True)\n",
        "    return df\n",
        "\n",
        "btc_1h = load_and_clean_csv(\"btc_1h.csv\")\n",
        "gold_1h = load_and_clean_csv(\"gold_1h.csv\")\n",
        "oil_1h = load_and_clean_csv(\"oil_1h.csv\")\n",
        "\n",
        "btc_4h = load_and_clean_csv(\"btc_4h.csv\")\n",
        "gold_4h = load_and_clean_csv(\"gold_4h.csv\")\n",
        "oil_4h = load_and_clean_csv(\"oil_4h.csv\")\n",
        "\n",
        "btc_1d = load_and_clean_csv(\"btc_daily.csv\")\n",
        "gold_1d = load_and_clean_csv(\"gold_daily.csv\")\n",
        "oil_1d = load_and_clean_csv(\"oil_daily.csv\")\n",
        "\n",
        "btc_1h.info(), btc_1h.head(2)\n"
      ],
      "id": "4ae53d830245b52f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2161 entries, 2025-03-01 05:00:00+00:00 to 2025-05-30 05:00:00+00:00\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       2161 non-null   float64\n",
            " 1   High       2161 non-null   float64\n",
            " 2   Low        2161 non-null   float64\n",
            " 3   Close      2161 non-null   float64\n",
            " 4   Adj Close  2161 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 101.3 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "                                    Open          High           Low  \\\n",
              " Datetime                                                              \n",
              " 2025-03-01 05:00:00+00:00  85599.203125  86199.703125  85599.203125   \n",
              " 2025-03-01 06:00:00+00:00  85017.718750  85614.648438  84933.656250   \n",
              " \n",
              "                                  Close  Adj Close  \n",
              " Datetime                                           \n",
              " 2025-03-01 05:00:00+00:00  86176.78125          0  \n",
              " 2025-03-01 06:00:00+00:00  85592.25000          0  )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:08:10.119615Z",
          "start_time": "2025-05-29T21:08:10.043188Z"
        },
        "id": "c5f3d09e5bf15c28"
      },
      "cell_type": "code",
      "source": [
        "def prepare_full_dataset(btc_df, gold_df, oil_df):\n",
        "    btc = btc_df.add_prefix('btc_')\n",
        "    gold = gold_df.add_prefix('gold_')\n",
        "    oil = oil_df.add_prefix('oil_')\n",
        "\n",
        "    df = btc.join([gold, oil], how='inner')\n",
        "    df.dropna(inplace=True)\n",
        "    df['Day'] = range(1, len(df) + 1)\n",
        "    df['Target'] = df['btc_Close'].shift(-1)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "df_1h = prepare_full_dataset(btc_1h, gold_1h, oil_1h)\n",
        "df_4h = prepare_full_dataset(btc_4h, gold_4h, oil_4h)\n",
        "df_1d = prepare_full_dataset(btc_1d, gold_1d, oil_1d)\n",
        "\n",
        "df_1h.to_csv(\"df_1h.csv\")\n",
        "df_4h.to_csv(\"df_4h.csv\")\n",
        "df_1d.to_csv(\"df_1d.csv\")"
      ],
      "id": "c5f3d09e5bf15c28",
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:09:01.050407Z",
          "start_time": "2025-05-29T21:08:10.174176Z"
        },
        "id": "a9641a785962a3db",
        "outputId": "636ff596-0fe9-4ecf-9462-28eabf684ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, models, metrics\n",
        "\n",
        "df_1h = pd.read_csv(\"df_1h.csv\")\n",
        "df_4h = pd.read_csv(\"df_4h.csv\")\n",
        "df_1d = pd.read_csv(\"df_1d.csv\")\n",
        "\n",
        "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
        "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
        "param_grid_dt = {'max_depth': [None]}\n",
        "param_grid_knn = {'n_neighbors': [3]}\n",
        "param_grid_ridge = {'alpha': [1.0]}\n",
        "\n",
        "def perform_grid_search(model, param_grid, X_train, y_train):\n",
        "    start_time = time.time()\n",
        "    search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "    search.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    return search.best_estimator_, train_time\n",
        "\n",
        "def train_ml(df, timeframe):\n",
        "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
        "    y = df[\"Target\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "    models_dict = {\n",
        "        \"Ridge\": (Ridge(), param_grid_ridge),\n",
        "        \"MLP\": (MLPRegressor(), param_grid_mlp),\n",
        "        \"LinearRegression\": (LinearRegression(), {}),\n",
        "        \"DecisionTree\": (DecisionTreeRegressor(), param_grid_dt),\n",
        "        \"KNN\": (KNeighborsRegressor(), param_grid_knn),\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid_rf),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for name, (model, params) in models_dict.items():\n",
        "        if params:\n",
        "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
        "        else:\n",
        "            start = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "            train_time = time.time() - start\n",
        "\n",
        "        start_pred = time.time()\n",
        "        preds = best_model.predict(X_test)\n",
        "        pred_time = time.time() - start_pred\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        r2 = r2_score(y_test, preds)\n",
        "        acc = 1 - (mae / y_test.mean())\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Timeframe\": timeframe,\n",
        "            \"TrainTime\": train_time,\n",
        "            \"PredictTime\": pred_time,\n",
        "            \"MAE\": mae,\n",
        "            \"R2\": r2,\n",
        "            \"Accuracy\": acc\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def sequence_maker(data, window_size, target_index):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size, target_index])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def train_rnn(X, y, tf, features):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(20, features)),\n",
        "        layers.SimpleRNN(20, return_sequences=True),\n",
        "        layers.SimpleRNN(20),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='mean_squared_error',\n",
        "        optimizer='adam',\n",
        "        metrics=[\n",
        "            metrics.MeanSquaredError(name='mse'),\n",
        "            metrics.MeanAbsoluteError(name='mae'),\n",
        "            metrics.MeanAbsolutePercentageError(name='mape'),\n",
        "            metrics.RootMeanSquaredError(name='rmse'),\n",
        "            metrics.R2Score(name='r2')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    start_train = time.time()\n",
        "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
        "    train_time = time.time() - start_train\n",
        "\n",
        "    start_pred = time.time()\n",
        "    results = model.evaluate(X_test, y_test, verbose=0)\n",
        "    pred_time = time.time() - start_pred\n",
        "\n",
        "    return {\n",
        "        \"Model\": \"RNN\",\n",
        "        \"Timeframe\": tf,\n",
        "        \"TrainTime\": train_time,\n",
        "        \"PredictTime\": pred_time,\n",
        "        \"MAE\": results[2],\n",
        "        \"R2\": results[5],\n",
        "        \"Accuracy\": 1 - (results[2] / np.mean(y_test))\n",
        "    }\n",
        "\n",
        "def run_rnn(df, tf):\n",
        "    df = df.drop(columns=[\"Datetime\"])\n",
        "    target_col = [col for col in df.columns if col.endswith(\"btc_Close\") or col == \"Close_btc\"]\n",
        "    target_col = target_col[0] if target_col else \"Close_btc\"\n",
        "    target_index = df.columns.get_loc(target_col)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df)\n",
        "    X, y = sequence_maker(scaled, 20, target_index)\n",
        "    return train_rnn(X, y, tf, features=X.shape[2])\n",
        "\n",
        "results = []\n",
        "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
        "    results.extend(train_ml(df, tf))\n",
        "    results.append(run_rnn(df, tf))\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ],
      "id": "a9641a785962a3db",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.75416e-21): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.3176e-21): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.83966e-22): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Model Timeframe  TrainTime  PredictTime           MAE  \\\n",
            "0              Ridge        1h   2.736880     0.003717  5.659375e+01   \n",
            "1                MLP        1h   0.515005     0.003915  5.222718e+04   \n",
            "2   LinearRegression        1h   0.011583     0.002928  5.666050e+01   \n",
            "3       DecisionTree        1h   0.184411     0.001998  9.527991e+02   \n",
            "4                KNN        1h   0.102630     0.033674  1.167362e+04   \n",
            "5       RandomForest        1h   3.118238     0.023622  9.215000e+02   \n",
            "6                RNN        1h  18.947366     0.122870  8.999836e-02   \n",
            "7              Ridge        4h   0.039914     0.001396  6.143221e+01   \n",
            "8                MLP        4h   0.148139     0.001775  1.112759e+07   \n",
            "9   LinearRegression        4h   0.002127     0.001254  6.145284e+01   \n",
            "10      DecisionTree        4h   0.040551     0.001529  1.204403e+03   \n",
            "11               KNN        4h   0.037931     0.001894  1.855431e+04   \n",
            "12      RandomForest        4h   0.731764     0.006239  8.896109e+02   \n",
            "13               RNN        4h  11.350446     0.130850  5.402077e-02   \n",
            "14             Ridge        1d   0.056454     0.001558  4.901447e+02   \n",
            "15               MLP        1d   1.018049     0.001904  8.563075e+04   \n",
            "16  LinearRegression        1d   0.003703     0.002037  4.901432e+02   \n",
            "17      DecisionTree        1d   0.229304     0.001563  1.146135e+04   \n",
            "18               KNN        1d   0.059673     0.007012  4.594122e+04   \n",
            "19      RandomForest        1d   5.169600     0.010908  1.185965e+04   \n",
            "20               RNN        1d  19.149693     0.248748  4.361469e-02   \n",
            "\n",
            "              R2    Accuracy  \n",
            "0   9.941109e-01    0.999482  \n",
            "1  -2.452912e+03    0.521606  \n",
            "2   9.941060e-01    0.999481  \n",
            "3   3.631006e-01    0.991272  \n",
            "4  -9.969530e+01    0.893071  \n",
            "5   3.087744e-01    0.991559  \n",
            "6  -4.362793e+00    0.903229  \n",
            "7   9.950789e-01    0.999436  \n",
            "8  -1.177398e+08 -101.103397  \n",
            "9   9.950694e-01    0.999436  \n",
            "10 -1.114874e-01    0.988949  \n",
            "11 -1.622462e+02    0.829751  \n",
            "12  5.238737e-01    0.991837  \n",
            "13 -1.742929e+00    0.941634  \n",
            "14  9.951890e-01    0.993846  \n",
            "15 -4.353131e+01   -0.075138  \n",
            "16  9.951890e-01    0.993846  \n",
            "17  2.470720e-02    0.856097  \n",
            "18 -7.752161e+00    0.423184  \n",
            "19 -5.785847e-02    0.851096  \n",
            "20  8.639377e-01    0.938778  \n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:09:01.283200Z",
          "start_time": "2025-05-29T21:09:01.160449Z"
        },
        "id": "35fc555ba80c5814"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_1h = pd.read_csv(\"df_1h.csv\")\n",
        "df_4h = pd.read_csv(\"df_4h.csv\")\n",
        "df_1d = pd.read_csv(\"df_1d.csv\")\n",
        "\n",
        "def process_for_classification(df):\n",
        "    df = df.drop(columns=[\"Target\"])\n",
        "    df[\"Benefit\"] = df[\"btc_Close\"] - df[\"btc_Open\"]\n",
        "    df[\"Target\"] = (df[\"Benefit\"] > 0).astype(int)\n",
        "    df[\"Target\"] = df[\"Target\"].shift(-1)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "df_1h_cls = process_for_classification(df_1h)\n",
        "df_4h_cls = process_for_classification(df_4h)\n",
        "df_1d_cls = process_for_classification(df_1d)\n",
        "\n",
        "df_1h_cls.to_csv(\"df_1h_class.csv\", index=False)\n",
        "df_4h_cls.to_csv(\"df_4h_class.csv\", index=False)\n",
        "df_1d_cls.to_csv(\"df_1d_class.csv\", index=False)"
      ],
      "id": "35fc555ba80c5814",
      "outputs": [],
      "execution_count": 7
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:09:24.293974Z",
          "start_time": "2025-05-29T21:09:01.346804Z"
        },
        "id": "5bb0626581cd02e7",
        "outputId": "73b62333-b2c9-4765-8e4d-1beccd4173bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, models, metrics\n",
        "\n",
        "df_1h = pd.read_csv(\"df_1h_class.csv\")\n",
        "df_4h = pd.read_csv(\"df_4h_class.csv\")\n",
        "df_1d = pd.read_csv(\"df_1d_class.csv\")\n",
        "\n",
        "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
        "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
        "param_grid_dt = {'max_depth': [None]}\n",
        "param_grid_knn = {'n_neighbors': [3]}\n",
        "\n",
        "def perform_grid_search(model, param_grid, X_train, y_train):\n",
        "    start_time = time.time()\n",
        "    search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    search.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    return search.best_estimator_, train_time\n",
        "\n",
        "def train_classification_models(df, timeframe):\n",
        "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
        "    y = df[\"Target\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "    models_dict = {\n",
        "        \"LogisticRegression\": (LogisticRegression(max_iter=500), {}),\n",
        "        \"MLP\": (MLPClassifier(), param_grid_mlp),\n",
        "        \"DecisionTree\": (DecisionTreeClassifier(), param_grid_dt),\n",
        "        \"KNN\": (KNeighborsClassifier(), param_grid_knn),\n",
        "        \"RandomForest\": (RandomForestClassifier(), param_grid_rf),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for name, (model, params) in models_dict.items():\n",
        "        if params:\n",
        "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
        "        else:\n",
        "            start = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "            train_time = time.time() - start\n",
        "\n",
        "        start_pred = time.time()\n",
        "        preds = best_model.predict(X_test)\n",
        "        pred_time = time.time() - start_pred\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Timeframe\": timeframe,\n",
        "            \"TrainTime\": train_time,\n",
        "            \"PredictTime\": pred_time,\n",
        "            \"Accuracy\": accuracy_score(y_test, preds),\n",
        "            \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
        "            \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
        "            \"F1\": f1_score(y_test, preds, zero_division=0)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def sequence_maker(data, window_size, target_index):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size, target_index])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def train_rnn_classifier(X, y, tf, features):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(20, features)),\n",
        "        layers.SimpleRNN(20, return_sequences=True),\n",
        "        layers.SimpleRNN(20),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=[\n",
        "            metrics.BinaryAccuracy(name='accuracy'),\n",
        "            metrics.Precision(name='precision'),\n",
        "            metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    start_train = time.time()\n",
        "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
        "    train_time = time.time() - start_train\n",
        "\n",
        "    start_pred = time.time()\n",
        "    eval_result = model.evaluate(X_test, y_test, verbose=0)\n",
        "    pred_time = time.time() - start_pred\n",
        "\n",
        "    return {\n",
        "        \"Model\": \"RNN\",\n",
        "        \"Timeframe\": tf,\n",
        "        \"TrainTime\": train_time,\n",
        "        \"PredictTime\": pred_time,\n",
        "        \"Accuracy\": eval_result[1],\n",
        "        \"Precision\": eval_result[2],\n",
        "        \"Recall\": eval_result[3],\n",
        "        \"F1\": 2 * eval_result[2] * eval_result[3] / (eval_result[2] + eval_result[3] + 1e-10)\n",
        "    }\n",
        "\n",
        "def run_rnn(df, tf):\n",
        "    df = df.drop(columns=[\"Datetime\"])\n",
        "    target_col = \"Target\"\n",
        "    target_index = df.columns.get_loc(target_col)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df)\n",
        "    X, y = sequence_maker(scaled, 20, target_index)\n",
        "    return train_rnn_classifier(X, y, tf, features=X.shape[2])\n",
        "\n",
        "results = []\n",
        "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
        "    results.extend(train_classification_models(df, tf))\n",
        "    results.append(run_rnn(df, tf))\n",
        "\n",
        "df_results_cls = pd.DataFrame(results)\n",
        "print(df_results_cls)"
      ],
      "id": "5bb0626581cd02e7",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model Timeframe  TrainTime  PredictTime  Accuracy  Precision  \\\n",
            "0   LogisticRegression        1h   0.032365     0.002019  0.478873   0.000000   \n",
            "1                  MLP        1h   0.300668     0.001796  0.514085   0.524752   \n",
            "2         DecisionTree        1h   0.313549     0.018931  0.485915   0.507937   \n",
            "3                  KNN        1h   0.296577     0.023079  0.507042   0.531250   \n",
            "4         RandomForest        1h   1.163121     0.007475  0.443662   0.463768   \n",
            "5                  RNN        1h  13.490292     0.120205  0.478571   0.512821   \n",
            "6   LogisticRegression        4h   0.019569     0.003134  0.416667   0.437500   \n",
            "7                  MLP        4h   0.154250     0.002010  0.500000   0.515152   \n",
            "8         DecisionTree        4h   0.053378     0.001791  0.611111   0.647059   \n",
            "9                  KNN        4h   0.051696     0.005382  0.444444   0.454545   \n",
            "10        RandomForest        4h   0.495700     0.008265  0.472222   0.500000   \n",
            "11                 RNN        4h  12.848305     0.140011  0.382353   0.363636   \n",
            "12  LogisticRegression        1d   0.022222     0.001992  0.461832   0.393443   \n",
            "13                 MLP        1d   0.438581     0.003094  0.511450   0.000000   \n",
            "14        DecisionTree        1d   0.342018     0.002857  0.541985   0.528571   \n",
            "15                 KNN        1d   0.284559     0.037687  0.496183   0.483607   \n",
            "16        RandomForest        1d   2.777067     0.007093  0.507634   0.497696   \n",
            "17                 RNN        1d  18.771770     0.214394  0.546154   0.560000   \n",
            "\n",
            "      Recall        F1  \n",
            "0   0.000000  0.000000  \n",
            "1   0.716216  0.605714  \n",
            "2   0.432432  0.467153  \n",
            "3   0.459459  0.492754  \n",
            "4   0.432432  0.447552  \n",
            "5   0.270270  0.353982  \n",
            "6   0.368421  0.400000  \n",
            "7   0.894737  0.653846  \n",
            "8   0.578947  0.611111  \n",
            "9   0.263158  0.333333  \n",
            "10  0.052632  0.095238  \n",
            "11  0.222222  0.275862  \n",
            "12  0.187500  0.253968  \n",
            "13  0.000000  0.000000  \n",
            "14  0.578125  0.552239  \n",
            "15  0.460938  0.472000  \n",
            "16  0.843750  0.626087  \n",
            "17  0.330709  0.415842  \n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-29T21:09:49.378844Z",
          "start_time": "2025-05-29T21:09:24.362434Z"
        },
        "id": "7b0cd93d6c31939e",
        "outputId": "6adb6f8b-c6e5-4337-e58e-6887c8811170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, models, metrics\n",
        "\n",
        "df_1h = pd.read_csv(\"df_1h_class.csv\")\n",
        "df_4h = pd.read_csv(\"df_4h_class.csv\")\n",
        "df_1d = pd.read_csv(\"df_1d_class.csv\")\n",
        "\n",
        "\n",
        "param_grid_rf = {'n_estimators': [50], 'max_depth': [None]}\n",
        "param_grid_mlp = {'hidden_layer_sizes': [(50,)], 'max_iter': [500]}\n",
        "param_grid_dt = {'max_depth': [None]}\n",
        "param_grid_knn = {'n_neighbors': [3]}\n",
        "\n",
        "def perform_grid_search(model, param_grid, X_train, y_train):\n",
        "    start_time = time.time()\n",
        "    search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    search.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    return search.best_estimator_, train_time\n",
        "\n",
        "def train_classification_models(df, timeframe):\n",
        "    X = df.drop(columns=[\"Target\", \"Datetime\"])\n",
        "    y = df[\"Target\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "    models_dict = {\n",
        "        \"LogisticRegression\": (LogisticRegression(max_iter=500), {}),\n",
        "        \"MLP\": (MLPClassifier(), param_grid_mlp),\n",
        "        \"DecisionTree\": (DecisionTreeClassifier(), param_grid_dt),\n",
        "        \"KNN\": (KNeighborsClassifier(), param_grid_knn),\n",
        "        \"RandomForest\": (RandomForestClassifier(), param_grid_rf),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for name, (model, params) in models_dict.items():\n",
        "        if params:\n",
        "            best_model, train_time = perform_grid_search(model, params, X_train, y_train)\n",
        "        else:\n",
        "            start = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "            train_time = time.time() - start\n",
        "\n",
        "        start_pred = time.time()\n",
        "        preds = best_model.predict(X_test)\n",
        "        pred_time = time.time() - start_pred\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Timeframe\": timeframe,\n",
        "            \"TrainTime\": train_time,\n",
        "            \"PredictTime\": pred_time,\n",
        "            \"Accuracy\": accuracy_score(y_test, preds),\n",
        "            \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
        "            \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
        "            \"F1\": f1_score(y_test, preds, zero_division=0)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def sequence_maker(data, window_size, target_index):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size, target_index])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def train_rnn_classifier(X, y, tf, features):\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.1, shuffle=False)\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(20, features)),\n",
        "        layers.SimpleRNN(20, return_sequences=True),\n",
        "        layers.SimpleRNN(20),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=[\n",
        "            metrics.BinaryAccuracy(name='accuracy'),\n",
        "            metrics.Precision(name='precision'),\n",
        "            metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    start_train = time.time()\n",
        "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
        "    train_time = time.time() - start_train\n",
        "\n",
        "    start_pred = time.time()\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
        "    pred_time = time.time() - start_pred\n",
        "\n",
        "    preds_df = pd.DataFrame({\n",
        "        'True': y_test.flatten(),\n",
        "        'Predicted': y_pred_class.flatten(),\n",
        "        'Probability': y_pred_prob.flatten()\n",
        "    })\n",
        "    preds_df.to_csv(f\"rnn_preds_{tf}.csv\", index=False)\n",
        "\n",
        "    acc = np.mean(y_pred_class.flatten() == y_test.flatten())\n",
        "    prec = precision_score(y_test, y_pred_class, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred_class, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_class, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"Model\": \"RNN\",\n",
        "        \"Timeframe\": tf,\n",
        "        \"TrainTime\": train_time,\n",
        "        \"PredictTime\": pred_time,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1\": f1\n",
        "    }\n",
        "\n",
        "def run_rnn(df, tf):\n",
        "    df = df.drop(columns=[\"Datetime\"])\n",
        "    target_col = \"Target\"\n",
        "    target_index = df.columns.get_loc(target_col)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df)\n",
        "    X, y = sequence_maker(scaled, 20, target_index)\n",
        "    return train_rnn_classifier(X, y, tf, features=X.shape[2])\n",
        "\n",
        "results = []\n",
        "for df, tf in zip([df_1h, df_4h, df_1d], [\"1h\", \"4h\", \"1d\"]):\n",
        "    results.extend(train_classification_models(df, tf))\n",
        "    results.append(run_rnn(df, tf))\n",
        "\n",
        "df_results_cls = pd.DataFrame(results)\n",
        "print(df_results_cls)"
      ],
      "id": "7b0cd93d6c31939e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bcc84c3f240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
            "                 Model Timeframe  TrainTime  PredictTime  Accuracy  Precision  \\\n",
            "0   LogisticRegression        1h   0.018364     0.002264  0.478873   0.000000   \n",
            "1                  MLP        1h   0.327026     0.001939  0.542254   0.666667   \n",
            "2         DecisionTree        1h   0.145365     0.002056  0.542254   0.558442   \n",
            "3                  KNN        1h   0.094268     0.011659  0.507042   0.531250   \n",
            "4         RandomForest        1h   1.105934     0.006121  0.507042   0.520833   \n",
            "5                  RNN        1h  19.820264     0.648466  0.478571   0.516129   \n",
            "6   LogisticRegression        4h   0.024432     0.002319  0.416667   0.437500   \n",
            "7                  MLP        4h   0.173702     0.002001  0.527778   1.000000   \n",
            "8         DecisionTree        4h   0.053479     0.002269  0.583333   0.600000   \n",
            "9                  KNN        4h   0.063440     0.006646  0.444444   0.454545   \n",
            "10        RandomForest        4h   0.488087     0.005486  0.361111   0.166667   \n",
            "11                 RNN        4h  10.759865     0.719487  0.470588   0.500000   \n",
            "12  LogisticRegression        1d   0.016264     0.002756  0.461832   0.393443   \n",
            "13                 MLP        1d   0.317169     0.002007  0.511450   0.000000   \n",
            "14        DecisionTree        1d   0.233034     0.001946  0.557252   0.540000   \n",
            "15                 KNN        1d   0.165021     0.025705  0.496183   0.483607   \n",
            "16        RandomForest        1d   2.008945     0.008205  0.538168   0.516129   \n",
            "17                 RNN        1d  25.261152     0.664803  0.534615   0.531915   \n",
            "\n",
            "      Recall        F1  \n",
            "0   0.000000  0.000000  \n",
            "1   0.243243  0.356436  \n",
            "2   0.581081  0.569536  \n",
            "3   0.459459  0.492754  \n",
            "4   0.675676  0.588235  \n",
            "5   0.216216  0.304762  \n",
            "6   0.368421  0.400000  \n",
            "7   0.105263  0.190476  \n",
            "8   0.631579  0.615385  \n",
            "9   0.263158  0.333333  \n",
            "10  0.052632  0.080000  \n",
            "11  0.555556  0.526316  \n",
            "12  0.187500  0.253968  \n",
            "13  0.000000  0.000000  \n",
            "14  0.632812  0.582734  \n",
            "15  0.460938  0.472000  \n",
            "16  0.875000  0.649275  \n",
            "17  0.393701  0.452489  \n"
          ]
        }
      ],
      "execution_count": 9
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}